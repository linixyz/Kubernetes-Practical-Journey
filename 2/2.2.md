# Namespace与资源分配

命名空间可以将Kubernetes集群划分为多个`虚拟集群`，每个命名空间中的对象、资源都是唯一的，命名空间无法互相嵌套。

## 为什么要使用命名空间

1. 集群分区：一个集群允许多个用户、多个团队使用，相互隔离、互不干扰（网络资源除外）；
2. 资源配额：管理员可以为每个命名空间配置资源消耗限制、创建对象数量，可以非常方便在集群內为不同项目组分配资源；

## 默认命名空间

默认情况下kubernetes拥有三个命名空间：

1. `default` 默认情况下，如果用户没有指定命名空间，创建的所有资源均在本命名空间下；所有运行在`default`命名空间下的程序`没有任何资源限制（CPU、内存）`，直到有人为命名空间设置资源配额为止。
2. `kube-public` 本命名空间下的资源所有用户可以公开读取。
3. `kube-system` kubernetes 系统、控制平面创建对象、资源的命名空间。

示例 YAML：`namespace.yaml`

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: viest
```

## 创建、查看、删除命名空间

```bash
# 一、可以应用上方示例yaml文件
kubectl apply -f namespace.yaml
 
# 二、可以通过命令行直接创建
kubectl create ns viest
 
# 查看命名空间列表
kubectl get ns
 
# 删除命名空间，将删除命名空间下所有对象（谨慎操作）
kubectl delete ns viest
```

## 用户绑定命名空间

在 `安全性.用户认证` 章节中我们从零开始创建了一个用户，并完成了对资源操作权限分配。这里将不在展开详细描述，如果你已经掌握用户创建、权限绑定，你还可以通过下方的步骤温习一下。

1. 创建用户证书，使用集群 CA 证书签署；
2. 创建 `kubeconfig` 配置文件，设置集群信息、用户认证信息、上下文信息；
3. 创建角色，分配不同资源的权限；
4. 用户绑定角色；

补充：如果想在系统用户层隔离，那么还需要创建一个系统用户，并将之前创建的 `kubeconfig` 配置文件拷贝至系统用户家目录下的`.kube` 目录中。

## 资源限额

前面创建了用户，也分配了权限，但并没有到终点。想象一下，有两个项目组A、B，且A、B两个项目组均部署了服务，两个项目组对服务资源并没有做任何限时，此时 A、B 项目组均准备进行压力测试，势必会造成A、B互相抢占资源的情况，也会影响测试结果的准确性。

### 对象无资源限额

1. 容器可无限制地使用内存、CPU，引发OOM事故（没有资源限制的容器被Kill的几率会更大）、CPU 资源浪费。
2. 即使容器没有显示指定资源限制，容器将会被分配命名空间默认限制，管理员可以使用 `LimitRange` 配置默认资源限额。

Type 与 资源限额关系

| Type                  | Resource    |
| --------------------- | ----------- |
| Container             | cpu、memory |
| Pod                   | cpu、memory |
| PersistentVolumeClaim | storage     |

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: default-resource-quota
  namespace: viest
spec:
  limites:
  - default: # 默认 limit 限额
      cpu: "2"
      memory: "600Mi"
    defaultRequest: # 默认 request 限额
      cpu: "0.5"
      memory: "300Mi"
    max: # 最大限额，limit 和 request 必须小于或等于
      cpu: "1"
      memory: "1Gi"
    min: # 最小限额，limit 和 request 必须大于或等于
      cpu: "0.5"
      memory: "300Mi"
    maxLimitRequestRatio: # limit 与 request 资源比例
      cpu: 2 # limit 不能超过 request 的 2 倍
      memory: 4 # limit 不能超过 request 的 4 倍
    type: Container # 限制类型，可选值为：Container、Pod、PersistentVolumeClaim
```

### 配置资源限额

下面我们将通过一个小实验，为`viest`命名空间分配额定的资源（如果不指定命名，受影响的将是 `default`命名空间），并创建几个服务，以此探寻资源配额策略。

示例 YAML

```yaml
# viest-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: cpu-05-memory-512
  namespace: viest
spec:
  hard:
    # 所有容器最多请求 0.5 CPU
    requests.cpu: "0.5"
    # 所有容器最多请求 512MB 内存
    requests.memory: 512Mi
    # 所有容器最多能够使用 1 CPU
    limits.cpu: "1"
    # 所有容器最多能够使用 1GB 内存
    limits.memory: 1Gi
```

创建资源 `ResourceQouta` 对象

```bash
kubectl apply -f viest-quota.yaml
```

查看资源配额信息

```bash
kubectl get quta -n viest
```

当然如果你想查看资源详细信息，也可以将对象输出为YAML格式

```bash
kubectl get quota cpu-05-memory-512 -n viest -o yaml
```

既然资源限制有了，怎么能不部署几个服务玩弄一波，下面我们部署几个简单Nginx服务，看下资源限制的策略。

这个服务内存用量被固定在了 513MB ~ 600MB 之间，如果容器运行的过程中内存使用超过 600MB，Kubernetes 将会终止此容器，如果容器允许被重启，则 kubelet 会尝试重启该容器，直到容器正确运行为止。

```yaml
# resource-quota-test-nginx-1.yaml
 
apiVersion: v1
kind: Pod
metadata:
  name: resource-quota-test-nginx-1
  namespace: viest
spec:
  containers:
  - name: test-nginx-1
    image: nginx
    ports:
    - containerPort: 80
    resources:
      limits:
        cpu: "0.7"
        memory: "600Mi"
      requests:
        cpu: "0.55"
        memory: "513Mi"
```

部署第一个测试Nginx服务

```bash
kubectl apply -f resource-quota-test-nginx-1.yaml
```

服务创建失败，从错误信息 `Error from server (Forbidden): error when creating "resource-quota-test-nginx-1.yaml": pods "resource-quota-test-nginx-1" is forbidden: exceeded quota: cpu-05-memory-512, requested: requests.cpu=550m,requests.memory=513Mi, used: requests.cpu=0,requests.memory=0, limited: requests.cpu=500m,requests.memory=512Mi`

可以看出如果请求资源大于资源配额时，kubernets 将终止对象创建。

我们将 Pod 请求资源大小稍作修改 `resources.requests.cpu` 改为 `0.3`、`resources.requests.memory` 改为 `256Mi`，再次尝试创建第一个测试服务

```bash
kubectl apply -f resource-quota-test-nginx-1.yaml
 
# 输出
# pod/resource-quota-test-nginx-1 created
```

> 提示：Pod创建成功，资源配额将无法修改。
>
> kubectl apply 应用更新你将会得到异常信息：The Pod "resource-quota-test-nginx-1" is invalid: spec: Forbidden: pod updates may not change fields other than `spec.containers[*].image`, `spec.initContainers[*].image`, `spec.activeDeadlineSeconds` or `spec.tolerations` (only additions to existing tolerations)

现在我们再尝试部署一个Nginx服务，我们可以查看命名空间配额余量

```bash
kubectl get quota -n viest
 
# 输出
# NAME                AGE    REQUEST                                                 LIMIT
# cpu-05-memory-512   143m   requests.cpu: 300m/500m, requests.memory: 256Mi/512Mi   limits.cpu: 700m/1, limits.memory: 600Mi/1Gi
```

请求配额余量：CPU 0.2、Memory 256M，总配额余量： CPU 0.3、Memory 424M，也就是说我们第二个服务的配额不能超过剩余配额，如果超过剩余配额将会出现第一次部署Nginx服务的情况，部署失败。

```yaml
# resource-quota-test-nginx-2.yaml
 
apiVersion: v1
kind: Pod
metadata:
  name: resource-quota-test-nginx-2
  namespace: viest
spec:
  containers:
  - name: test-nginx-2
    image: nginx
    ports:
    - containerPort: 80
    resources:
      limits:
        cpu: "0.3"
        memory: "424Mi"
      requests:
        cpu: "0.2"
        memory: "256Mi"
```

当 `resource-quota-test-nginx-2` 创建成功时，由管理员设定的命名空间配额资源已被全部使用，此时创建一个没有指定资源限时的Pod，我们看下会发生什么

```yaml
# resource-quota-test-nginx-3.yaml
 
apiVersion: v1
kind: Pod
metadata:
  name: resource-quota-test-nginx-3
  namespace: viest
spec:
  containers:
  - name: test-nginx-3
    image: nginx
    ports:
    - containerPort: 80
```

当应用 `resource-quota-test-nginx-3.yaml` 时，将得到错误信息：`Error from server (Forbidden): error when creating "resource-quota-test-nginx-3.yaml": pods "resource-quota-test-nginx-3" is forbidden: failed quota: cpu-05-memory-512: must specify limits.cpu,limits.memory,requests.cpu,requests.memory`，似乎 kubernetes 并没有自动为Pod创建资源配额，但是`viest` 命名空间下确实没有剩余配额了。

为了验证这个问题，我们预设几个场景，并且逐一实验：

1. 维持现有资源配额，将 `resource-quota-test-nginx-2` Pod 删除，使命名空间资源配额始终有余量，再次尝试部署 `resource-quota-test-nginx-3`，结果没有任何变化。
2. 删除内存资源配额，只保留CPU资源配额，再次尝试部署 `resource-quota-test-nginx-3` ，结果没有任何变化。
3. 删除CPU资源配额，只保留内存资源配额，再次尝试部署 `resource-quota-test-nginx-3` ，结果没有任何变化。

经过以上三个场景的测试，不难发现，当命名空间存在资源配额时，必须指定Pod资源限制，否则将无法创建对象。